import matplotlib.pyplot as plt
from sklearn.metrics import classification_report
from sklearn.metrics import multilabel_confusion_matrix, ConfusionMatrixDisplay


def plot_result(model_name, real_y, predict_y, labels, log_dir=None, plot=True, isTest=False):
    """
    This method implement classification_report (built into sklearn) to vesualize performance of model, 
    and record performance into log.txt file. It has two status. If isTest is true, it will report all 
    performance results in classification_report.

    Args:
        model_name (str): The model to be evaluated.
        real_y (pd.core.frame.DataFrame): labels
        predict_y (pd.core.frame.DataFrame): Predicted results.
        labels (list): All categories to be classified.
        log_dir (str, optional): Dir for the log.txt file. Defaults to None.
        plot (bool, optional): True, it will print out result. Otherwise, not. Defaults to True.
        isTest (bool, optional): True, it will return all result generated by classification_report. Otherwise, not. Defaults to False.
    """
    if isTest:
        report_dir = classification_report(y_true=real_y, y_pred=predict_y, labels=labels, digits=4)
    else:
        report_dir = classification_report(y_true=real_y, y_pred=predict_y, labels=labels, digits=4, output_dict=True)
    result = "=== {} report ===\n".format(model_name)
    if isTest:
        result += report_dir
    else:
        result += "=== Accuracy {:.2f}%\n".format(report_dir["accuracy"]*100)
        result += "=== Precision {:.2f}%   Recall {:.2f}%    Sensitivity {:.2f}%    Specificity {:.2f}%    F1 {:.4f}\n".format(
                report_dir["1"]["precision"]*100,
                report_dir["1"]["recall"]*100,
                report_dir["2"]["precision"]*100,
                report_dir["2"]["recall"]*100,
                report_dir["1"]["f1-score"]
            )
    if log_dir != None:
        log = open(log_dir + "/log.txt", "a+")
        log.write(result+"\n")
        log.close()
    if plot:
        print(result)



def plot_confusion_matrix(real_y, predict_y, labels):
    """
    This method will plot confusion matrix for multilabel results.

    Args:
        real_y (pd.core.frame.DataFrame): labels
        predict_y (pd.core.frame.DataFrame): Predicted results.
        labels (list): All category names to be classified.
    """
    for cm in multilabel_confusion_matrix(real_y, predict_y, labels=labels):
        print(cm)
        ConfusionMatrixDisplay(cm).plot()
        plt.show()
    plt.close("all")

def tight_layout(model, predict_x, predict_y,labels, save_dir=None, plot=False):
    """
    This method will plot confusion matrix.

    Args:
        model (str): The model to be evaluated.
        real_y (pd.core.frame.DataFrame): labels
        predict_y (pd.core.frame.DataFrame): Predicted results.
        labels (list): All category names to be classified.
        save_dir (str, optional): Dir for saving images. Defaults to None.
        plot (bool, optional): True, it will show it out. Otherwise, not. Defaults to False.
    """
    ConfusionMatrixDisplay.from_estimator(
        model, predict_x, predict_y, display_labels=labels, xticks_rotation="vertical"
    )
    plt.tight_layout()
    if save_dir != None:
        plt.savefig(save_dir)
    if plot:
        plt.show()
    plt.close("all")
